from typing import List, Dict, Optional, Any
import json
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from app.db.session import SessionLocal
from app.models.setting import SystemSetting
from app.models.workflow import Workflow
from app.core.config import settings
from pydantic import BaseModel
from enum import Enum


class RoundtablePhase(str, Enum):
    NOT_STARTED = "not_started"
    SELECTING_EXPERTS = "selecting_experts"
    DISCUSSING = "discussing"
    SUMMARIZING = "summarizing"
    COMPLETED = "completed"


class RoundtableExpert(BaseModel):
    id: str
    name: str
    description: str
    system_prompt: str
    domain: Optional[str] = None


class RoundtableState(BaseModel):
    topic: str = ""
    experts: List[RoundtableExpert] = []
    phase: RoundtablePhase = RoundtablePhase.NOT_STARTED
    current_speaker_idx: int = -1
    current_speaker_name: Optional[str] = None
    discussion_history: List[Dict[str, str]] = []  # [{speaker, content}]
    round_count: int = 0
    has_consensus: bool = False
    should_continue: bool = True  # ä¸»æŒäººåˆ¤æ–­æ˜¯å¦ç»§ç»­
    summary: Optional[str] = None


# Global state for roundtable
_ROUNDTABLE_STATE = RoundtableState()


class RoundtableService:
    """åœ†æ¡Œä¼šè®®æœåŠ¡ - åè°ƒä¸“å®¶è®¨è®º"""
    
    # é¢†åŸŸå…³é”®è¯æ˜ å°„
    DOMAIN_KEYWORDS = {
        "é‡‘èæ ¸å¿ƒ": ["è‚¡ç¥¨", "åŸºé‡‘", "æŠ•èµ„", "é£é™©", "å®è§‚", "åŠ å¯†", "äº¤æ˜“", "é‡‘è", "è´§å¸", "å¸‚åœº"],
        "ç§‘æŠ€å‰æ²¿": ["ä»£ç ", "ç®—æ³•", "æ¶æ„", "é«˜å¹¶å‘", "æ•°æ®", "ç³»ç»Ÿ", "ç¼–ç¨‹", "æŠ€æœ¯", "å¼€å‘", "è½¯ä»¶", "AI"],
        "å®‰å…¨æ³•åŠ¡": ["å®‰å…¨", "æ¼æ´", "åˆè§„", "æ³•å¾‹", "éšç§", "æ”»å‡»", "é˜²æŠ¤"],
        "äº§å“æˆ˜ç•¥": ["äº§å“", "å¢é•¿", "ç”¨æˆ·", "å•†ä¸š", "åˆ›ä¸š", "å¸‚åœº", "æˆ˜ç•¥"],
        "è®¾è®¡åˆ›æ„": ["UI", "è®¾è®¡", "æ¸¸æˆ", "ç¾å­¦", "ä½“éªŒ", "è§†è§‰", "äº¤äº’"],
        "ç§‘å­¦ç†è®º": ["æ¨¡å‹", "ç»Ÿè®¡", "ç§‘å­¦", "ç†è®º", "ç‰©ç†", "æ•°å­¦", "å®éªŒ"],
        "äººæ–‡ç¤¾ç§‘": ["å†å²", "å¿ƒç†", "è¡Œä¸º", "å‘¨æœŸ", "ç¤¾ä¼š", "æ–‡åŒ–"]
    }
    
    EXPERT_DOMAINS = {
        "Macro Strategist": "é‡‘èæ ¸å¿ƒ",
        "Quant Analyst": "é‡‘èæ ¸å¿ƒ",
        "Risk Manager": "é‡‘èæ ¸å¿ƒ",
        "Crypto Native": "é‡‘èæ ¸å¿ƒ",
        "System Architect": "ç§‘æŠ€å‰æ²¿",
        "Algo Geek": "ç§‘æŠ€å‰æ²¿",
        "DevOps Master": "ç§‘æŠ€å‰æ²¿",
        "Data Alchemist": "ç§‘æŠ€å‰æ²¿",
        "Security Spec Ops": "å®‰å…¨æ³•åŠ¡",
        "Legal Counsel": "å®‰å…¨æ³•åŠ¡",
        "Product Visionary": "äº§å“æˆ˜ç•¥",
        "Startup Founder": "äº§å“æˆ˜ç•¥",
        "User Researcher": "äº§å“æˆ˜ç•¥",
        "Design Lead": "è®¾è®¡åˆ›æ„",
        "Game Producer": "è®¾è®¡åˆ›æ„",
        "Space Architect": "è®¾è®¡åˆ›æ„",
        "Complex Systems Physicist": "ç§‘å­¦ç†è®º",
        "Statistician": "ç§‘å­¦ç†è®º",
        "Evolutionary Biologist": "ç§‘å­¦ç†è®º",
        "Historian": "äººæ–‡ç¤¾ç§‘",
        "Behavioral Psychologist": "äººæ–‡ç¤¾ç§‘",
    }
    
    @staticmethod
    def get_state() -> RoundtableState:
        return _ROUNDTABLE_STATE
    
    @staticmethod
    def _get_llm(max_tokens: int = 500):
        db = SessionLocal()
        try:
            db_api_key = db.query(SystemSetting).filter(SystemSetting.key == "openai_api_key").first()
            db_base_url = db.query(SystemSetting).filter(SystemSetting.key == "openai_base_url").first()
            
            final_api_key = db_api_key.value if (db_api_key and db_api_key.value) else settings.OPENAI_API_KEY
            final_base_url = db_base_url.value if (db_base_url and db_base_url.value) else settings.OPENAI_BASE_URL
            
            if not final_api_key:
                return None
            
            model = "deepseek-chat"
            if final_base_url and "moonshot" in final_base_url:
                model = "moonshot-v1-8k"
            elif not final_base_url or "openai" in str(final_base_url):
                model = "gpt-3.5-turbo"

            return ChatOpenAI(
                model=model,
                api_key=final_api_key,
                base_url=final_base_url,
                temperature=0.7,
                max_tokens=max_tokens
            )
        except Exception as e:
            print(f"Error init LLM: {e}")
            return None
        finally:
            db.close()
    
    @staticmethod
    def _get_all_experts() -> List[Workflow]:
        db = SessionLocal()
        try:
            workflows = db.query(Workflow).filter(
                ~Workflow.id.in_(["wf_general", "wf_agent"])
            ).all()
            return workflows
        finally:
            db.close()
    
    @staticmethod
    def _get_expert_domain(expert_name: str) -> str:
        for key, domain in RoundtableService.EXPERT_DOMAINS.items():
            if key in expert_name:
                return domain
        return "é€šç”¨"
    
    @staticmethod
    def _select_experts_by_topic(topic: str, all_experts: List[Workflow], count: int = 6) -> List[RoundtableExpert]:
        llm = RoundtableService._get_llm(max_tokens=300)
        
        if not llm:
            import random
            selected = random.sample(all_experts, min(count, len(all_experts)))
            return [RoundtableExpert(
                id=e.id, name=e.name, description=e.description,
                system_prompt=e.system_prompt,
                domain=RoundtableService._get_expert_domain(e.name)
            ) for e in selected]
        
        expert_list = "\n".join([f"- ID: {e.id}, åç§°: {e.name}, æè¿°: {e.description}" for e in all_experts])
        
        prompt = f"""ä½ æ˜¯ä¸€ä½åœ†æ¡Œä¼šè®®çš„ç»„ç»‡è€…ã€‚æ ¹æ®ä»¥ä¸‹è®®é¢˜ï¼Œä»ä¸“å®¶åˆ—è¡¨ä¸­é€‰æ‹© {count} ä½æœ€ç›¸å…³çš„å‚ä¼šè€…ã€‚

è®®é¢˜: {topic}

ä¸“å®¶åˆ—è¡¨:
{expert_list}

è¯·è¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼ŒåŒ…å«é€‰ä¸­ä¸“å®¶çš„ IDã€‚åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
ä¾‹å¦‚: ["id1", "id2", "id3", "id4", "id5", "id6"]"""

        try:
            response = llm.invoke([HumanMessage(content=prompt)])
            content = response.content.strip()
            
            if "```" in content:
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
            
            selected_ids = json.loads(content)
            
            selected = []
            for expert in all_experts:
                if expert.id in selected_ids:
                    selected.append(RoundtableExpert(
                        id=expert.id,
                        name=expert.name,
                        description=expert.description,
                        system_prompt=expert.system_prompt,
                        domain=RoundtableService._get_expert_domain(expert.name)
                    ))
            
            if len(selected) < 5:
                remaining = [e for e in all_experts if e.id not in selected_ids]
                import random
                extra = random.sample(remaining, min(5 - len(selected), len(remaining)))
                for e in extra:
                    selected.append(RoundtableExpert(
                        id=e.id, name=e.name, description=e.description,
                        system_prompt=e.system_prompt,
                        domain=RoundtableService._get_expert_domain(e.name)
                    ))
            
            return selected[:7]
            
        except Exception as e:
            print(f"Expert selection error: {e}")
            import random
            selected = random.sample(all_experts, min(count, len(all_experts)))
            return [RoundtableExpert(
                id=e.id, name=e.name, description=e.description,
                system_prompt=e.system_prompt,
                domain=RoundtableService._get_expert_domain(e.name)
            ) for e in selected]
    
    @staticmethod
    def start_roundtable(topic: str) -> RoundtableState:
        global _ROUNDTABLE_STATE
        
        all_experts = RoundtableService._get_all_experts()
        selected_experts = RoundtableService._select_experts_by_topic(topic, all_experts)
        
        expert_names = [e.name for e in selected_experts]
        
        _ROUNDTABLE_STATE = RoundtableState(
            topic=topic,
            experts=selected_experts,
            phase=RoundtablePhase.DISCUSSING,
            current_speaker_idx=-1,
            discussion_history=[{
                "speaker": "ä¸»æŒäºº",
                "content": f"## åœ†æ¡Œä¼šè®®å¼€å§‹\n\n**è®®é¢˜**ï¼š{topic}\n\n**å‚ä¼šä¸“å®¶**ï¼š\n" + "\n".join([f"- {name}" for name in expert_names]) + "\n\nè¯·å„ä½ä¸“å®¶ä»ä¸“ä¸šè§’åº¦å‘è¡¨è§‚ç‚¹ï¼Œå¯ä»¥æå‡ºè´¨ç–‘å’Œä¸åŒæ„è§ã€‚"
            }],
            round_count=0,
            has_consensus=False,
            should_continue=True
        )
        
        return _ROUNDTABLE_STATE
    
    @staticmethod
    def next_speaker() -> RoundtableState:
        state = _ROUNDTABLE_STATE
        
        if state.phase == RoundtablePhase.COMPLETED:
            return state
        
        if not state.experts:
            return state
        
        # æ¯è½®ç»“æŸåï¼Œä¸»æŒäººåˆ¤æ–­æ˜¯å¦ç»§ç»­
        if state.current_speaker_idx == len(state.experts) - 1:
            state.round_count += 1
            # ä¸»æŒäººè¯„ä¼°
            moderator_decision = RoundtableService._moderator_evaluate(state)
            state.discussion_history.append({
                "speaker": "ä¸»æŒäºº",
                "content": moderator_decision["comment"]
            })
            state.should_continue = moderator_decision["should_continue"]
            
            if not state.should_continue:
                # è‡ªåŠ¨ç”Ÿæˆæ€»ç»“
                return RoundtableService.generate_summary()
        
        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä½ä¸“å®¶
        state.current_speaker_idx = (state.current_speaker_idx + 1) % len(state.experts)
        
        current_expert = state.experts[state.current_speaker_idx]
        state.current_speaker_name = current_expert.name
        
        # ç”Ÿæˆå‘è¨€
        content = RoundtableService._generate_speech(current_expert, state)
        
        state.discussion_history.append({
            "speaker": current_expert.name,
            "content": content
        })
        
        return state
    
    @staticmethod
    def _moderator_evaluate(state: RoundtableState) -> Dict[str, Any]:
        """ä¸»æŒäººè¯„ä¼°è®¨è®ºè¿›å±•ï¼Œå†³å®šæ˜¯å¦ç»§ç»­"""
        llm = RoundtableService._get_llm(max_tokens=300)
        
        if not llm:
            return {"should_continue": state.round_count < 5, "comment": "è¯·ç»§ç»­è®¨è®ºã€‚"}
        
        # æ„å»ºè®¨è®ºæ‘˜è¦
        recent_history = state.discussion_history[-10:]
        history_text = "\n".join([f"ã€{h['speaker']}ã€‘: {h['content'][:100]}..." for h in recent_history])
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åœ†æ¡Œä¼šè®®ä¸»æŒäººã€‚è¯·è¯„ä¼°å½“å‰è®¨è®ºè¿›å±•ã€‚

è®®é¢˜: {state.topic}
å·²è¿›è¡Œè½®æ•°: {state.round_count}
è®¨è®ºæ‘˜è¦:
{history_text}

è¯·åˆ¤æ–­ï¼š
1. è®¨è®ºæ˜¯å¦å·²ç»å……åˆ†ï¼Ÿå„æ–¹è§‚ç‚¹æ˜¯å¦éƒ½å·²è¡¨è¾¾ï¼Ÿ
2. æ˜¯å¦è¿˜æœ‰é‡è¦åˆ†æ­§éœ€è¦è¿›ä¸€æ­¥è®¨è®ºï¼Ÿ
3. æ˜¯å¦å¯ä»¥è¿›å…¥æ€»ç»“é˜¶æ®µï¼Ÿ

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "should_continue": true/false,
  "comment": "ä½ çš„ä¸»æŒäººç‚¹è¯„ï¼ˆ100å­—ä»¥å†…ï¼Œç”¨markdownæ ¼å¼ï¼‰"
}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚æ³¨æ„ï¼šè‡³å°‘è®¨è®º 5 è½®æ‰èƒ½ç»“æŸã€‚å½“å‰å·²è®¨è®º {state.round_count} è½®ã€‚"""

        try:
            response = llm.invoke([HumanMessage(content=prompt)])
            content = response.content.strip()
            
            if "```" in content:
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
            
            result = json.loads(content)
            return result
            
        except Exception as e:
            print(f"Moderator evaluation error: {e}")
            # é»˜è®¤5è½®åç»“æŸ
            if state.round_count >= 5:
                return {"should_continue": False, "comment": "è®¨è®ºå·²è¾ƒä¸ºå……åˆ†ï¼Œè¿›å…¥æ€»ç»“é˜¶æ®µã€‚"}
            return {"should_continue": True, "comment": "è¯·ç»§ç»­æ·±å…¥è®¨è®ºã€‚"}
    
    @staticmethod
    def _generate_speech(expert: RoundtableExpert, state: RoundtableState) -> str:
        """ç”Ÿæˆä¸“å®¶å‘è¨€ - æ›´åŠ å®¢è§‚ä¸¥è‚ƒ"""
        llm = RoundtableService._get_llm(max_tokens=400)
        
        if not llm:
            return "(ç³»ç»Ÿæç¤º): æœªé…ç½® API Keyï¼Œæ— æ³•ç”Ÿæˆå‘è¨€ã€‚"
        
        recent_history = state.discussion_history[-6:]
        history_text = "\n".join([f"ã€{h['speaker']}ã€‘: {h['content']}" for h in recent_history])
        
        # æ›´ä¸¥è‚ƒã€å®¢è§‚çš„æç¤ºè¯
        system_prompt = f"""{expert.system_prompt}

ä½ æ­£åœ¨å‚åŠ ä¸€åœº**ä¸¥è‚ƒçš„ä¸“ä¸šåœ†æ¡Œè®¨è®ºä¼š**ã€‚
è®®é¢˜æ˜¯ï¼š{state.topic}

ã€é‡è¦è¦æ±‚ã€‘ï¼š
1. ä¿æŒå®¢è§‚ã€ç†æ€§ã€ä¸“ä¸šçš„æ€åº¦
2. ä¸è¦æ­ç»´æˆ–èµç¾å…¶ä»–ä¸“å®¶
3. å¦‚æœæœ‰ä¸åŒæ„è§ï¼Œç›´æ¥æå‡ºï¼Œä¸è¦å§”å©‰å®¢å¥—
4. ç”¨æ•°æ®ã€äº‹å®ã€é€»è¾‘æ¥æ”¯æ’‘è§‚ç‚¹
5. å¯ä»¥è´¨ç–‘å…¶ä»–ä¸“å®¶çš„è§‚ç‚¹ï¼ŒæŒ‡å‡ºæ½œåœ¨é—®é¢˜
6. ä½¿ç”¨ Markdown æ ¼å¼ç»„ç»‡å›ç­”ï¼ˆå¯ç”¨åŠ ç²—ã€åˆ—è¡¨ã€æ ‡é¢˜ç­‰ï¼‰"""

        user_prompt = f"""æœ€è¿‘çš„è®¨è®º:
{history_text}

å½“å‰æ˜¯ç¬¬ {state.round_count + 1} è½®ã€‚

è¯·ä»ä½ çš„ä¸“ä¸šè§’åº¦å‘è¨€ï¼š
- ç›´æ¥è¡¨è¾¾è§‚ç‚¹ï¼Œä¸è¦å¯’æš„
- å¦‚æœ‰ä¸åŒæ„è§ï¼Œæ˜ç¡®æŒ‡å‡ºå¹¶è¯´æ˜ç†ç”±
- æä¾›å…·ä½“çš„è§è§£æˆ–å»ºè®®
- å­—æ•°ï¼š150-250å­—
- ä½¿ç”¨ Markdown æ ¼å¼"""

        try:
            response = llm.invoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ])
            return response.content
        except Exception as e:
            return f"(å‘è¨€ç”Ÿæˆé”™è¯¯): {str(e)}"
    
    @staticmethod
    def _check_consensus(state: RoundtableState) -> bool:
        if state.round_count >= 3:
            return True
        return False
    
    @staticmethod
    def generate_summary() -> RoundtableState:
        state = _ROUNDTABLE_STATE
        
        if state.phase == RoundtablePhase.COMPLETED:
            return state
        
        state.phase = RoundtablePhase.SUMMARIZING
        
        llm = RoundtableService._get_llm(max_tokens=1000)
        
        if not llm:
            state.summary = "æœªé…ç½® API Keyï¼Œæ— æ³•ç”Ÿæˆæ€»ç»“ã€‚"
            state.phase = RoundtablePhase.COMPLETED
            return state
        
        all_history = "\n\n".join([f"ã€{h['speaker']}ã€‘: {h['content']}" for h in state.discussion_history])
        
        prompt = f"""è¯·ä¸ºä»¥ä¸‹åœ†æ¡Œè®¨è®ºç”Ÿæˆä¸€ä»½**å®Œæ•´ã€ç»“æ„åŒ–çš„æ€»ç»“**ã€‚

è®®é¢˜: {state.topic}

è®¨è®ºå†…å®¹:
{all_history}

è¯·ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

## ğŸ“‹ æ ¸å¿ƒç»“è®º
ï¼ˆè®¨è®ºè¾¾æˆçš„ä¸»è¦å…±è¯†ï¼Œ2-3ç‚¹ï¼‰

## ğŸ’¡ å…³é”®æ´å¯Ÿ
ï¼ˆå„ä¸“å®¶è´¡çŒ®çš„é‡è¦è§‚ç‚¹ï¼ŒæŒ‰ä¸“å®¶æˆ–ä¸»é¢˜åˆ†ç±»ï¼‰

## âš ï¸ äº‰è®®ä¸åˆ†æ­§
ï¼ˆè®¨è®ºä¸­å‡ºç°çš„ä¸åŒæ„è§ï¼‰

## ğŸ¯ è¡ŒåŠ¨å»ºè®®
ï¼ˆåŸºäºè®¨è®ºçš„å…·ä½“å¯æ‰§è¡Œå»ºè®®ï¼‰

## ğŸ“Œ æ³¨æ„äº‹é¡¹
ï¼ˆæ½œåœ¨é£é™©ã€é™åˆ¶æ¡ä»¶ï¼‰

æ€»ç»“è¦å……åˆ†ã€å…¨é¢ã€ç»“æ„æ¸…æ™°ã€‚"""

        try:
            response = llm.invoke([HumanMessage(content=prompt)])
            state.summary = response.content
        except Exception as e:
            state.summary = f"æ€»ç»“ç”Ÿæˆé”™è¯¯: {str(e)}"
        
        state.phase = RoundtablePhase.COMPLETED
        state.discussion_history.append({
            "speaker": "ä¼šè®®æ€»ç»“",
            "content": state.summary
        })
        
        return state
    
    @staticmethod
    def reset() -> RoundtableState:
        global _ROUNDTABLE_STATE
        _ROUNDTABLE_STATE = RoundtableState()
        return _ROUNDTABLE_STATE
