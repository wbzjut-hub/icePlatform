from sqlalchemy.orm import Session
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage
from app.core.config import settings
from app.models.chat import ChatSession, ChatMessage
from app.models.workflow import Workflow
from app.models.setting import SystemSetting  # <--- [æ–°å¢] å¯¼å…¥è®¾ç½®æ¨¡å‹
from app.services.tools import get_todo_tools
import datetime
import json


class AIService:
    # è·å–æ‰€æœ‰å¯ç”¨å·¥å…·çš„æ³¨å†Œè¡¨
    def _get_tool_registry(self, db: Session):
        raw_tools = get_todo_tools(db)
        return {t.name: t for t in raw_tools}

    async def chat_with_workflow(self, db: Session, message: str, session_id: str, workflow_id: str = "wf_agent"):
        # 1. è·å–å·¥ä½œæµé…ç½®
        workflow = db.query(Workflow).filter(Workflow.id == workflow_id).first()

        # ğŸŒŸ ä¿®å¤é€»è¾‘ï¼šç¡®ä¿ workflow å’Œ prompt ä¸€å®šæœ‰å€¼
        if not workflow:
            # å›é€€æœºåˆ¶ï¼šå¦‚æœæ‰¾ä¸åˆ°æŒ‡å®šçš„å·¥ä½œæµï¼Œä½¿ç”¨é»˜è®¤çš„
            workflow = Workflow(
                name="Fallback",
                system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ IcePlatform Agentã€‚å½“å‰æ—¶é—´æ˜¯: {current_time}ã€‚",
                tools_config=[]
            )

        # 2. åŠ¨æ€æ„å»º System Prompt (æ³¨å…¥æ—¶é—´)
        week_days = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"]
        now = datetime.datetime.now()
        week_day_str = week_days[now.weekday()]
        today_str = now.strftime("%Y-%m-%d %H:%M")

        # ğŸŒŸ ç¡®ä¿å˜é‡è¢«å®šä¹‰
        final_system_prompt = workflow.system_prompt.replace("{current_time}", f"{today_str} ({week_day_str})")

        # 3. åŠ¨æ€åŠ è½½å·¥å…·
        tool_registry = self._get_tool_registry(db)
        # ç­›é€‰å·¥å…·
        active_tools = []
        if workflow.tools_config:
            active_tools = [tool_registry[name] for name in workflow.tools_config if name in tool_registry]

        # ================== [æ–°å¢] åŠ¨æ€é…ç½®è¯»å–é€»è¾‘ ==================

        # A. ä»æ•°æ®åº“è·å–é…ç½®
        db_api_key = db.query(SystemSetting).filter(SystemSetting.key == "openai_api_key").first()
        db_base_url = db.query(SystemSetting).filter(SystemSetting.key == "openai_base_url").first()

        # B. ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„é…ç½® (DB > Env > é»˜è®¤)
        final_api_key = db_api_key.value if (db_api_key and db_api_key.value) else settings.OPENAI_API_KEY
        final_base_url = db_base_url.value if (db_base_url and db_base_url.value) else settings.OPENAI_BASE_URL

        # C. å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœæ²¡æœ‰ Keyï¼Œç›´æ¥è¿”å›æç¤ºï¼Œä¸è°ƒç”¨ LLM
        if not final_api_key:
            return {
                "reply": "ğŸš« **æœªé…ç½® API Key**\n\nè¯·ç‚¹å‡»å³ä¸Šè§’çš„è®¾ç½®å›¾æ ‡ (âš™ï¸) é…ç½®æ‚¨çš„ AI æœåŠ¡å•†å¯†é’¥ (å¦‚ DeepSeek / OpenAI)ã€‚",
                "usage": None
            }

        # D. è‡ªåŠ¨åˆ¤æ–­æ¨¡å‹åç§° (æ ¹æ® Base URL)
        # å¦‚æœ URL åŒ…å« moonshot ç”¨ moonshot-v1-8kï¼ŒåŒ…å« deepseek ç”¨ deepseek-chatï¼Œå¦åˆ™é»˜è®¤ gpt-3.5-turbo
        target_model = "deepseek-chat"
        if final_base_url and "moonshot" in final_base_url:
            target_model = "moonshot-v1-8k"
        elif final_base_url and "deepseek" in final_base_url:
            target_model = "deepseek-chat"
        elif not final_base_url or "openai" in str(final_base_url):
            target_model = "gpt-3.5-turbo"

        # 4. åˆå§‹åŒ– LLM
        llm = ChatOpenAI(
            model=target_model,
            temperature=0.3,
            api_key=final_api_key,  # ä½¿ç”¨åŠ¨æ€ Key
            base_url=final_base_url  # ä½¿ç”¨åŠ¨æ€ URL
        )

        # ================== [ç»“æŸ] ==================

        if active_tools:
            llm_with_tools = llm.bind_tools(active_tools)
        else:
            llm_with_tools = llm

        # 5. æ„å»ºä¸Šä¸‹æ–‡
        history_messages = [SystemMessage(content=final_system_prompt)]

        # è·å–æœ€è¿‘å†å²è®°å½•
        recent_msgs = db.query(ChatMessage).filter(ChatMessage.session_id == session_id).order_by(
            ChatMessage.created_at.asc()).limit(8).all()
        for msg in recent_msgs:
            if msg.role == "user":
                history_messages.append(HumanMessage(content=msg.content))
            else:
                history_messages.append(AIMessage(content=msg.content))

        # åŠ ä¸Šå½“å‰æ¶ˆæ¯
        if not history_messages or history_messages[-1].content != message:
            history_messages.append(HumanMessage(content=message))

        # å®šä¹‰é»˜è®¤è¿”å›å€¼
        usage_data = None
        reply_text = ""
        executed_actions = []  # ğŸŒŸ è¿½è¸ªæ‰§è¡Œçš„åŠ¨ä½œ

        # 6. æ‰§è¡Œæ¨ç†
        try:
            ai_response = llm_with_tools.invoke(history_messages)

            # æ•è· Token (ç¬¬ä¸€è½®)
            if hasattr(ai_response, 'response_metadata'):
                usage_data = ai_response.response_metadata.get('token_usage')

            if hasattr(ai_response, 'tool_calls') and ai_response.tool_calls:
                history_messages.append(ai_response)

                for tool_call in ai_response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    tool_id = tool_call["id"]

                    print(f"ğŸ”§ Workflow [{workflow.name}] Action: {tool_name}")

                    selected_tool = tool_registry.get(tool_name)
                    if selected_tool:
                        try:
                            tool_output = selected_tool.invoke(tool_args)
                            executed_actions.append(tool_name)  # è®°å½•æˆåŠŸè°ƒç”¨çš„å·¥å…·
                        except Exception as tool_err:
                            tool_output = f"Error executing {tool_name}: {tool_err}"
                    else:
                        tool_output = f"Error: Tool '{tool_name}' not allowed."

                    history_messages.append(ToolMessage(tool_call_id=tool_id, content=str(tool_output)))

                # ç¬¬äºŒè½®è°ƒç”¨
                final_response = llm_with_tools.invoke(history_messages)
                reply_text = final_response.content

                # æ›´æ–° Token
                if hasattr(final_response, 'response_metadata'):
                    usage_data = final_response.response_metadata.get('token_usage')
            else:
                reply_text = ai_response.content

        except Exception as e:
            print(f"Workflow Error: {e}")
            reply_text = f"Error: {str(e)}"

        return {
            "reply": reply_text,
            "usage": usage_data,
            "actions": executed_actions # ğŸŒŸ è¿”å›åŠ¨ä½œåˆ—è¡¨
        }


ai_service = AIService()